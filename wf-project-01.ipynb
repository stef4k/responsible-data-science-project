{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c8f238-7f91-4150-a7d7-72e8cf37bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1715ab-c7ed-48e1-8a07-9c477a66f226",
   "metadata": {},
   "source": [
    "## Load Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c09b850-68f8-4bb2-991b-dbc6beb4e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only needed columns\n",
    "feature_names = [\n",
    "    \"Age\", \"Workclass\", \"Education\", \n",
    "    \"Occupation\", \"Relationship\", \"Race\", \n",
    "    \"Sex\", \"Capital Gain\", \"Capital Loss\", \n",
    "    \"Hours per week\", \"Country\", \"label\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "  np.genfromtxt('dataset/adult.csv', delimiter=', ', dtype=str, usecols=(0,1,3,6,7,8,9,10,11,12,13,14)),    \n",
    "  columns=feature_names\n",
    ")\n",
    "\n",
    "# Drop missing values denoted as ?\n",
    "cols = list(df.columns)\n",
    "df[cols] = df[cols].replace(['?'], np.nan)\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "# Declare categorical columns\n",
    "categorical_columns=[\n",
    "   \"Workclass\", \"Education\", \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Country\", \"label\"\n",
    "]\n",
    "\n",
    "# Assign type to features\n",
    "for feature in feature_names:\n",
    "    if feature in categorical_columns:\n",
    "        df[feature] = df[feature].astype(\"category\")\n",
    "    else:\n",
    "        df[feature] = df[feature].astype(\"int\")\n",
    "\n",
    "# Make bins for age and hours per week\n",
    "df['Age'] = pd.cut(df['Age'], bins=[16, 35 , 90],labels=['Young','Aged'])\n",
    "df[\"Hours per week\"] = pd.cut(\n",
    "            x=df[\"Hours per week\"],\n",
    "            bins=[0.9, 25, 39, 40, 55, 100],\n",
    "            labels=[\"PartTime\", \"MidTime\", \"FullTime\", \"OverTime\", \"BrainDrain\"])\n",
    "\n",
    "# Replace \"Husband\" and \"Wife\" values with the unisex \"Married\"\n",
    "df[\"Relationship\"] = df[\"Relationship\"].replace('Husband','Married')\n",
    "df[\"Relationship\"] = df[\"Relationship\"].replace('Wife','Married')\n",
    "\n",
    "# Will have income >50k (1 or 0)\n",
    "df[\"label\"] = df[\"label\"].replace('>50K',1)\n",
    "df[\"label\"] = df[\"label\"].replace('<=50K',0)\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82abdd0-926e-4946-b25b-5385d141f842",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e112092b-8a61-4565-a13e-2e7def2a39f2",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fd9277-5fbe-409e-972d-14042d76eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing to train model\n",
    "from omnixai.data.tabular import Tabular\n",
    "from omnixai.preprocessing.tabular import TabularTransform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tabular_data = Tabular(\n",
    "   df,\n",
    "   categorical_columns=[\n",
    "  \"Age\", \"Workclass\", \"Education\", \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Hours per week\", \"Country\"\n",
    "],\n",
    "   target_column='label'\n",
    ")\n",
    "transformer = TabularTransform().fit(tabular_data)\n",
    "class_names = transformer.class_names\n",
    "x = transformer.transform(tabular_data)\n",
    "\n",
    "# Split data into training and (validation + test) datasets\n",
    "train, X_temp, train_labels, y_temp  = \\\n",
    "    train_test_split(x[:, :-1], x[:, -1], train_size=0.70, random_state = 123)\n",
    "\n",
    "# Split data validation and test sets\n",
    "val, test, val_labels, test_labels = train_test_split(X_temp, y_temp, test_size=0.5, random_state=123)\n",
    "\n",
    "test_labels = test_labels.astype(int)\n",
    "\n",
    "print('Training data shape:   {}'.format(train.shape))\n",
    "print('Validation data shape:  {}'.format(val.shape))\n",
    "print('Test data shape:        {}'.format(test.shape))\n",
    "\n",
    "# Train a Random Forest model\n",
    "model = RandomForestClassifier(random_state=123)\n",
    "model.fit(train, train_labels)\n",
    "\n",
    "predict_function=lambda z: model.predict_proba(transformer.transform(z))\n",
    "\n",
    "# Convert the transformed data back to Tabular instances\n",
    "train_data = transformer.invert(train)\n",
    "test_data = transformer.invert(test)\n",
    "\n",
    "display(tabular_data.target_column)\n",
    "display(train_labels[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2976258-ac1a-4bac-b9b7-dfad5f7ede64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Predictions\n",
    "test_df = test_data.to_pd()\n",
    "test_df[\"label\"] = test_labels\n",
    "predictions = model.predict(test)\n",
    "test_df[\"prediction\"] = predictions\n",
    "\n",
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04761915-3a1a-4df6-8947-ce527263a62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f'Test: {accuracy=:.4f}')\n",
    "\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "\n",
    "TN = cm[0][0]\n",
    "FN = cm[1][0]\n",
    "TP = cm[1][1]\n",
    "FP = cm[0][1]\n",
    "print(f\"Test: {TP=}, {TN=}, {FP=}, {FN=}\")\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, )\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46760902",
   "metadata": {},
   "source": [
    "## Fairness\n",
    "Now the fairness will be analyzed\n",
    "\n",
    "First we import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a1992-ab24-4e1b-a52e-b1bf19be7a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "import random\n",
    "from aif360.metrics import ClassificationMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9380a5-042f-4188-85f8-bc485232370b",
   "metadata": {},
   "source": [
    "Since for the fairness analysis, we can not use the Tabular data, we create a new dataframe with the transformed values of TabularTransform. This is because we need to have access to a dataframe structure containing the binarized values (for age, sex and all categorical attributes) and not the categorical values (e.g. Young/Aged, Female/Male etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e414966-fefd-47c8-84ed-0dafc180a348",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = transformer.get_feature_names()\n",
    "# Last column is the label which is not included in the get_feature_names\n",
    "column_names.append('label')\n",
    "\n",
    "fairness_dataset = pd.DataFrame(x, columns=column_names)\n",
    "fairness_dataset.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67441c00-008d-4a34-9076-febbfee68d45",
   "metadata": {},
   "source": [
    "As seen below there are four columns for the protected attributes of sex and age. Two boolean columns for each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f4bcd7-c809-4f64-8719-d5930e832940",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_dataset[['Age_Aged', 'Age_Young', 'Sex_Male', 'Sex_Female']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cd035d-69e3-48d3-8e6e-5497bf6695b0",
   "metadata": {},
   "source": [
    "We decide only to keep `Age_Aged` and `Sex_Male`, and renaming those to columns to `Age` and `Sex` meaning that:\n",
    "- when `Sex` is 0, the person is female and when when `Sex` is 1, the person is male\n",
    "- when `Age` is 0, the person is young and  when `Age` is 0, the person is aged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2263308a-4403-4d99-87aa-9339cc1bb5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_dataset = fairness_dataset.drop(columns=['Age_Young', 'Sex_Female'])\n",
    "fairness_dataset.rename(columns={'Age_Aged': 'Age', 'Sex_Male': 'Sex'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f149d9-c863-4efa-8a4f-67a62ab460ef",
   "metadata": {},
   "source": [
    "Next we want to ensure that we train the classifier on the exact same data as the previous normal classifier, keeping the train, validation and test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ee85cf-da53-48df-adee-04f476f739ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and (validation + test) datasets\n",
    "train, X_temp, _, y_temp  = \\\n",
    "    train_test_split(fairness_dataset, fairness_dataset.label, train_size=0.70, random_state = 123)\n",
    "\n",
    "# Split data validation and test sets\n",
    "val, test, _, _ = train_test_split(X_temp, y_temp, test_size=0.5, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ef0d7f-e38f-427b-8ebd-34d99f8653af",
   "metadata": {},
   "source": [
    "Now we can transform the previous data structures into BinaryLabelDatasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e8fad-eab3-4451-8278-f056bc2b68ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to BinaryLabelDataset\n",
    "dataset_fair_train = BinaryLabelDataset(df=train, label_names=['label'], protected_attribute_names=['Age', 'Sex'])\n",
    "dataset_fair_valid = BinaryLabelDataset(df=val, label_names=['label'], protected_attribute_names=['Age', 'Sex'])\n",
    "dataset_fair_test = BinaryLabelDataset(df=test, label_names=['label'], protected_attribute_names=['Age', 'Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a5ee5a-fe59-43ae-9169-095a99009cb7",
   "metadata": {},
   "source": [
    "Now the group fairness of the classifier will be assessed, assuming the protected attributes are Age, Sex.\n",
    "\n",
    "We assume that:\n",
    "- Young age (corresponding to 0) is one unprivileged group and Aged (corresponding to 1) is one privileged group\n",
    "- Female sex is one unprivileged (corresponding to 0) group and male sex (corresponding to 1) is one privileged group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c29bcf-b09b-4a1b-8ca2-f3a840d6a66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'Age':1,\n",
    "                      'Sex':1}]\n",
    "unprivileged_groups = [{'Age': 0,\n",
    "                       'Sex':0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782e714e-9d6c-418d-bd8b-819c10c4d85a",
   "metadata": {},
   "source": [
    "Since there is a significant difference in the positive rates and true positive rate thus there is unfairness. Actually, the priviliged groups (aged and male) has 37% more chance to be predicted as >50k income comparing to the unprivileged group (young, female)\n",
    "\n",
    "Now, we will try to mitigate this bias in the training dataset by using the `Reweighing algorithm`. By reweighing we ensure that there is better fairness when we compare the positive rates between privileged and unprivileged groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f7198-4ec2-4a0f-8f7d-d5029ef45a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "dataset_transf_train = RW.fit_transform(dataset_fair_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dcf4e9-000c-4bd0-bb7f-3940baac0526",
   "metadata": {},
   "source": [
    "### Fair classifier\n",
    "\n",
    "Since reweighting does not achieve the goal of $0$ statistical parity difference or Equal opportunity difference, we will oversample the underprivileged classes (female young) and undersample the privileged classes (male aged) to teach the classifier to be more fair. After some experimentation, it was decided:\n",
    "- $750$ extra samples of young female with income >50k were randomly oversampled in the training data, and random weights of values between $[1.2,1.6]$ were given for each sample\n",
    "- $1500$ samples of aged male with income >50k were randomly undersampled in the training data (completely removed from the training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d4be2-61e1-4082-979d-c32d026ce8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed to reproduce results\n",
    "random.seed(1)\n",
    "\n",
    "# Number of over-samples produced for training dataset\n",
    "number_oversamples = 750\n",
    "# Number of under-samples to be removed for training dataset\n",
    "number_undersamples = 1500\n",
    "\n",
    "# Train and target data\n",
    "X_train = dataset_transf_train.features\n",
    "y_train = dataset_transf_train.labels.ravel()\n",
    "\n",
    "# Resampled data structures\n",
    "X_train_resampled = X_train.copy()\n",
    "y_train_resampled = y_train.copy()\n",
    "weights_resampled = dataset_transf_train.instance_weights.copy()\n",
    "\n",
    "# list to keep for indexes of undersamples (to be deleted after)\n",
    "list_indexes_undersamples = []\n",
    "# List to keep the over_samples and counters of oversamples and undersamples\n",
    "oversamples = []\n",
    "counter_oversamples = 0\n",
    "counter_undersamples = 0\n",
    "\n",
    "# Iterate over the whole training dataset\n",
    "for counter in range(len(X_train)):\n",
    "    # Only append rows that contain young female since this is the heavily underprivileged class\n",
    "    if (X_train[counter][0] == 0) and (X_train[counter][1] == 0) and (y_train[counter] == 1)\\\n",
    "        and (counter_oversamples < number_oversamples):\n",
    "        oversamples.append(X_train[counter].copy())\n",
    "        counter_oversamples += 1\n",
    "    # Store index of rows that contain aged male since this is the heavily overprivileged class\n",
    "    if ((X_train[counter][0] == 1) or (X_train[counter][1] == 1)) and (y_train[counter] == 1)\\\n",
    "        and (counter_undersamples < number_undersamples):\n",
    "        list_indexes_undersamples.append(counter)\n",
    "        counter_undersamples += 1\n",
    "    # When number of extra oversamples and undersamples is reached, stop loop\n",
    "    if (counter_oversamples == number_oversamples) and (counter_undersamples == number_undersamples):\n",
    "        break\n",
    "    counter += 1\n",
    "\n",
    "# Remove all indexes of undersamples\n",
    "X_train_resampled = np.delete(X_train_resampled, list_indexes_undersamples, axis=0)\n",
    "y_train_resampled = np.delete(y_train_resampled, list_indexes_undersamples)\n",
    "weights_resampled = np.delete(weights_resampled, list_indexes_undersamples)\n",
    "\n",
    "\n",
    "# Only assign positive labels to favor underprivileged class \n",
    "arr = np.array([1 for i in range(number_oversamples)])\n",
    "\n",
    "# Append extra samples and labels to the training data and \n",
    "y_train_resampled = np.append(y_train_resampled, arr)\n",
    "X_train_resampled = np.vstack([X_train_resampled, oversamples])\n",
    "# Randomize weights of extra samples to take values between 1 and 1.5\n",
    "weights_resampled = np.append(weights_resampled, np.array([random.uniform(1.2, 1.6) for i in range(number_oversamples)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621f0b73-2378-4fce-a54d-bafb2c38a49a",
   "metadata": {},
   "source": [
    "Now we can train the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03636381-824f-40c2-bf21-96486fc2838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fair_reweighted = RandomForestClassifier(random_state=123)\n",
    "model_fair_reweighted.fit(X_train_resampled, y_train_resampled, sample_weight=weights_resampled)\n",
    "\n",
    "X_test = dataset_fair_test.features\n",
    "y_test = dataset_fair_test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb5a56f-13a1-48fc-a1fd-9febf87f9d5f",
   "metadata": {},
   "source": [
    "Next predict the test data <b> based on the threshold </b> found in the fairness analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a3357-cf61-42e8-83e0-4742eef04306",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "threshold_fairness = 0.4555\n",
    "# positive class index\n",
    "pos_ind = 1\n",
    "\n",
    "for item in model_fair_reweighted.predict_proba(X_test)[:,pos_ind].reshape(-1,1):\n",
    "    if item >=  threshold_fairness:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c918ff8d-7e7f-434d-bdc6-5108fe334976",
   "metadata": {},
   "source": [
    "Last let's print the metrics for this classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a0060e-40e1-40cf-a064-3bf59639ca8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_fair = accuracy_score(y_test, predictions)\n",
    "print(f'Test: {accuracy_fair=:.4f}')\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "TN = cm[0][0]\n",
    "FN = cm[1][0]\n",
    "TP = cm[1][1]\n",
    "FP = cm[0][1]\n",
    "print(f\"Test: {TP=}, {TN=}, {FP=}, {FN=}\")\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, )\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8856cf-2370-44aa-9c7b-c878dc2b312f",
   "metadata": {},
   "source": [
    "Also the fairness metric of `equal opportunity difference` will be printed for the fair classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70a783d-6843-432c-8c67-853b61dc7bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation of predictions dateset - transform into BinaryLabelDataset with right predictions based on the fairness threshold\n",
    "dataset_fair_test_pred = dataset_fair_test.copy(deepcopy=True)\n",
    "dataset_fair_test_pred.scores = model_fair_reweighted.predict_proba(X_test)[:,pos_ind].reshape(-1,1)\n",
    "fav_inds = dataset_fair_test_pred.scores > threshold_fairness\n",
    "dataset_fair_test_pred.labels[fav_inds] = dataset_fair_test_pred.favorable_label\n",
    "dataset_fair_test_pred.labels[~fav_inds] = dataset_fair_test_pred.unfavorable_label\n",
    "\n",
    "# Calculate metric\n",
    "equal_opportunity_diff_metric = ClassificationMetric(dataset_fair_test, dataset_fair_test_pred, \n",
    "                                            unprivileged_groups=unprivileged_groups,\n",
    "                                            privileged_groups=privileged_groups).equal_opportunity_difference()\n",
    "print(f'Equal opportunity difference: {equal_opportunity_diff_metric=:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc4139a",
   "metadata": {},
   "source": [
    "## Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5174f0",
   "metadata": {},
   "source": [
    "To start off, let's define a new dataframe similar to the one above, the set the values of p and q for both sensitive attributes and compute for epsilon. For now, both attributes are assumed to have the same p and q, but they can be redefined to any value as seen fit.\n",
    "\n",
    "Random response is applied to the relevant attributes afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdf0b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "# randomized response \n",
    "def rand_resp(x, p=0.75, q=0.75):\n",
    "    toss = random.random()\n",
    "    if x == 0:\n",
    "        y = 0 if toss <= q else 1\n",
    "    else:\n",
    "        y = 1 if toss <= p else 0\n",
    "    return y\n",
    "\n",
    "def get_epsilon(p=0.75, q=0.75):\n",
    "    return math.log( max(q/(1-p), p/(1-q)) )\n",
    "\n",
    "# apply attribute to a attribute\n",
    "def privatize_attribute(column, true_label, false_label, p, q):\n",
    "    # Convert labels to binary values\n",
    "    binary_values = column.apply(lambda x: 1 if x == true_label else 0).values\n",
    "    \n",
    "    # Apply randomized response\n",
    "    privatized_values = pd.Series([rand_resp(x, p, q) for x in binary_values], index=column.index)\n",
    "\n",
    "    # Convert back to original labels\n",
    "    return privatized_values.apply(lambda x: true_label if x == 1 else false_label)\n",
    "\n",
    "# Create a copy of the original data\n",
    "df_private = df.copy(deep=True)\n",
    "\n",
    "# Set values of p and q\n",
    "p_age, q_age = 0.8, 0.8\n",
    "p_sex, q_sex = 0.8, 0.8  \n",
    "\n",
    "epsilon_age = get_epsilon(p_age, q_age)\n",
    "epsilon_sex = get_epsilon(p_sex, q_sex)\n",
    "print(f\"We will apply {epsilon_age:.3f}-LDP setting p={p_age}, q={q_age} for age \\\n",
    "AND {epsilon_sex:.3f}-LDP setting p={p_sex}, q={q_sex} for sex.\")\n",
    "\n",
    "# Apply randomized response to Age and Sex\n",
    "df_private['Age'] = privatize_attribute(df_private['Age'], 'Aged', 'Young', p_age, q_age)\n",
    "df_private['Sex'] = privatize_attribute(df_private['Sex'], 'Male', 'Female', p_sex, q_sex)\n",
    "\n",
    "# Display the new DataFrame\n",
    "df_private.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61ccbd6",
   "metadata": {},
   "source": [
    "We compute the cross-tabulation on the original data and private data to estimate how many people exist in value combinations of the two sensitive attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc92407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Showing cross tabulation\n",
    "print(\"\\nOriginal Cross-tabulation:\")\n",
    "original_crosstab = pd.crosstab(df['Age'], df['Sex'])\n",
    "print(tabulate(original_crosstab, headers='keys', tablefmt='pretty'))\n",
    "\n",
    "print(\"\\nPrivatized Cross-tabulation:\")\n",
    "privatized_crosstab = pd.crosstab(df_private['Age'], df_private['Sex'])\n",
    "print(tabulate(privatized_crosstab, headers='keys', tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246286dc",
   "metadata": {},
   "source": [
    "Compute the error between the privatized and the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dc3e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_error(true_value, estimated_value):\n",
    "\n",
    "    if true_value == 0:\n",
    "        # If the true value is zero, the percent error is undefined.\n",
    "        return float('inf')\n",
    "    \n",
    "    # Calculate the absolute difference\n",
    "    abs_error = abs(true_value - estimated_value)\n",
    "        \n",
    "    # Calculate the percent error\n",
    "    pct_error = (abs_error / true_value) * 100\n",
    "        \n",
    "    return pct_error\n",
    "\n",
    "\n",
    "error_female_young = pct_error(original_crosstab[\"Female\"][\"Young\"], privatized_crosstab[\"Female\"][\"Young\"])\n",
    "print(f\"The percent error for young female responses is: {error_female_young}%\")\n",
    "\n",
    "error_female_aged = pct_error(original_crosstab[\"Female\"][\"Aged\"], privatized_crosstab[\"Female\"][\"Aged\"])\n",
    "print(f\"The percent error for aged female responses is: {error_female_aged}%\")\n",
    "\n",
    "error_male_young = pct_error(original_crosstab[\"Male\"][\"Young\"], privatized_crosstab[\"Male\"][\"Young\"])\n",
    "print(f\"The percent error for young male responses is: {error_male_young}%\")\n",
    "\n",
    "error_male_aged = pct_error(original_crosstab[\"Male\"][\"Aged\"], privatized_crosstab[\"Male\"][\"Aged\"])\n",
    "print(f\"The percent error for aged male responses is: {error_male_aged}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0807f1",
   "metadata": {},
   "source": [
    "Estimating the actual responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446671ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate(column, p=0.75, q=0.75):\n",
    "    n_people = len(column)\n",
    "    n_reported = np.sum(column.astype(int))\n",
    "    return (n_reported/n_people + q - 1)/(p+q-1)*n_people\n",
    "\n",
    "# insert estimate here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f980363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Private Classifier\n",
    "\n",
    "tabular_data_private = Tabular(\n",
    "   df_private,\n",
    "   categorical_columns=[\n",
    "  \"Age\", \"Workclass\", \"Education\", \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Hours per week\", \"Country\"\n",
    "],\n",
    "   target_column='label'\n",
    ")\n",
    "transformer_private = TabularTransform().fit(tabular_data_private)\n",
    "class_names = transformer_private.class_names\n",
    "x_private = transformer_private.transform(tabular_data_private)\n",
    "\n",
    "# Split data into training and (validation + test) datasets\n",
    "train_private, X_private_temp, train_labels_private, y_private_temp  = \\\n",
    "    train_test_split(x_private[:, :-1], x_private[:, -1], train_size=0.70, random_state = 123)\n",
    "\n",
    "# Split data validation and test sets\n",
    "val_private, test_private, val_labels_private, test_labels_private = train_test_split(X_private_temp, y_private_temp, test_size=0.5, random_state=123)\n",
    "\n",
    "test_labels_private = test_labels_private.astype(int)\n",
    "\n",
    "print('Private Classfier')\n",
    "print('Training data shape:   {}'.format(train_private.shape))\n",
    "print('Validation data shape:  {}'.format(val_private.shape))\n",
    "print('Test data shape:        {}'.format(test_private.shape))\n",
    "\n",
    "# Train a Random Forest model\n",
    "model_private = RandomForestClassifier(random_state=123)\n",
    "model_private.fit(train_private, train_labels_private)\n",
    "\n",
    "predict_function_private=lambda z: model_private.predict_proba(transformer_private.transform(z))\n",
    "\n",
    "# # Convert the transformed data back to Tabular instances\n",
    "train_data_private = transformer_private.invert(train_private)\n",
    "test_data_private = transformer_private.invert(test_private)\n",
    "\n",
    "display(tabular_data_private.target_column)\n",
    "display(train_labels_private[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e25585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Predictions\n",
    "test_df_private = test_data_private.to_pd()\n",
    "test_df_private[\"label\"] = test_labels_private\n",
    "predictions_private = model_private.predict(test_private)\n",
    "test_df_private[\"prediction\"] = predictions_private\n",
    "\n",
    "test_df_private.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cca831",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_private = accuracy_score(test_labels_private, predictions_private)\n",
    "print(f'Test: {accuracy_private=:.4f}')\n",
    "\n",
    "cm_private = confusion_matrix(test_labels_private, predictions_private)\n",
    "\n",
    "TN = cm_private[0][0]\n",
    "FN = cm_private[1][0]\n",
    "TP = cm_private[1][1]\n",
    "FP = cm_private[0][1]\n",
    "print(f\"Test: {TP=}, {TN=}, {FP=}, {FN=}\")\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_private, )\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4359d9",
   "metadata": {},
   "source": [
    "The accuracy lowered as expected. Implementing differential privacy involves adding noise to the training process to protect individual data points. This added noise can degrade the model's accuracy, especially as epsilon decreases. Lower epsilon values correspond to stronger privacy guarantees but also result in greater noise, which can lead to decreased model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7800b9b-8e48-4cd8-b73b-2afd7029ba90",
   "metadata": {},
   "source": [
    "## Privacy and Fairness\n",
    "Now a fair version of the private classifier will be analyzed\n",
    "\n",
    "We use the private data set from earlier and transform it to be compatible with the fairness classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4098f668-9a77-4171-8655-d80c30af9a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "random.seed(123)\n",
    "\n",
    "# Step 1: Assign feature names and create DataFrame\n",
    "column_names_pf = transformer_private.get_feature_names()\n",
    "column_names_pf.append('label')  # Add the label column\n",
    "privatized_data_fair = pd.DataFrame(x, columns=column_names_pf)\n",
    "privatized_data_fair.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207b5129-c106-45d8-b901-07e7df97cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "privatized_data_fair[['Age_Aged', 'Age_Young', 'Sex_Male', 'Sex_Female']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274d47ea-d2ef-43a8-a90c-744992337cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "privatized_data_fair = privatized_data_fair.drop(columns=['Age_Young', 'Sex_Female'])\n",
    "privatized_data_fair.rename(columns={'Age_Aged': 'Age', 'Sex_Male': 'Sex'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5847f50-bcaf-4c5d-b335-433b6be147b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, validation, and test sets\n",
    "train_priv, X_temp_priv, _, y_temp_priv = train_test_split(\n",
    "    privatized_data_fair, privatized_data_fair.label, train_size=0.70, random_state=123\n",
    ")\n",
    "val_priv, test_priv, _, _ = train_test_split(X_temp_priv, y_temp_priv, test_size=0.5, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31da9d39-5dd9-412f-b0e9-8d01ec3073cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BinaryLabelDataset for privatized data\n",
    "dataset_priv_train = BinaryLabelDataset(\n",
    "    df=train_priv, label_names=['label'], protected_attribute_names=['Age', 'Sex']\n",
    ")\n",
    "dataset_priv_valid = BinaryLabelDataset(\n",
    "    df=val_priv, label_names=['label'], protected_attribute_names=['Age', 'Sex']\n",
    ")\n",
    "dataset_priv_test = BinaryLabelDataset(\n",
    "    df=test_priv, label_names=['label'], protected_attribute_names=['Age', 'Sex']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35025612-d8ac-44b3-ab88-2b1fa3eb45f8",
   "metadata": {},
   "source": [
    "### Reweighing\n",
    "Use the Reweighing technique on the privatized dataset to adjust for fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb10e9-208b-47f6-94de-c49fc1126278",
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'Age':1,\n",
    "                      'Sex':1}]\n",
    "unprivileged_groups = [{'Age': 0,\n",
    "                       'Sex':0}]\n",
    "# Apply Reweighing\n",
    "RW_priv = Reweighing(\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups\n",
    ")\n",
    "dataset_transf_priv_train = RW_priv.fit_transform(dataset_priv_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8908324a-4e79-40b6-a62f-2e8734e919c4",
   "metadata": {},
   "source": [
    "### Resampling\n",
    "Resample the data to correct for underprivileged and overprivileged classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68989826-bba6-4c33-8cfc-3a1213858613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and target data\n",
    "X_train_priv = dataset_transf_priv_train.features\n",
    "y_train_priv = dataset_transf_priv_train.labels.ravel()\n",
    "weights_priv = dataset_transf_priv_train.instance_weights.copy()\n",
    "\n",
    "# Resampling parameters\n",
    "number_oversamples = 750\n",
    "number_undersamples = 1500\n",
    "\n",
    "# Resampling logic (use the same logic from Part 2)\n",
    "oversamples_priv = []\n",
    "undersamples_indexes_priv = []\n",
    "counter_oversamples_priv = 0\n",
    "counter_undersamples_priv = 0\n",
    "\n",
    "for i in range(len(X_train_priv)):\n",
    "    # Over-sample underprivileged group (Young Female, 0,0)\n",
    "    if (X_train_priv[i][0] == 0) and (X_train_priv[i][1] == 0) and (y_train_priv[i] == 1) \\\n",
    "            and counter_oversamples_priv < number_oversamples:\n",
    "        oversamples_priv.append(X_train_priv[i].copy())\n",
    "        counter_oversamples_priv += 1\n",
    "    # Under-sample overprivileged group (Aged Male, 1,1)\n",
    "    if ((X_train_priv[i][0] == 1) or (X_train_priv[i][1] == 1)) and (y_train_priv[i] == 1) \\\n",
    "            and counter_undersamples_priv < number_undersamples:\n",
    "        undersamples_indexes_priv.append(i)\n",
    "        counter_undersamples_priv += 1\n",
    "    # Stop when limits are reached\n",
    "    if counter_oversamples_priv == number_oversamples and counter_undersamples_priv == number_undersamples:\n",
    "        break\n",
    "\n",
    "# Remove under-samples\n",
    "X_train_priv_resampled = np.delete(X_train_priv, undersamples_indexes_priv, axis=0)\n",
    "y_train_priv_resampled = np.delete(y_train_priv, undersamples_indexes_priv)\n",
    "weights_priv_resampled = np.delete(weights_priv, undersamples_indexes_priv)\n",
    "\n",
    "# Add over-samples\n",
    "X_train_priv_resampled = np.vstack([X_train_priv_resampled, oversamples_priv])\n",
    "y_train_priv_resampled = np.append(y_train_priv_resampled, [1] * len(oversamples_priv))\n",
    "weights_priv_resampled = np.append(weights_priv_resampled, np.random.uniform(1.2, 1.6, len(oversamples_priv)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badf4f89-888b-4fe5-bae0-f1a4cbfc1e9c",
   "metadata": {},
   "source": [
    "### Train Privacy + Fairness Classifier\n",
    "Train a classifier using the resampled, reweighted, and privacy-preserved dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76967f4d-fa1d-4f89-92dd-eec3c7cb5bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest model\n",
    "model_priv_fair = RandomForestClassifier(random_state=123)\n",
    "model_priv_fair.fit(X_train_priv_resampled, y_train_priv_resampled, sample_weight=weights_priv_resampled)\n",
    "\n",
    "# Test data\n",
    "X_test_priv = dataset_priv_test.features\n",
    "y_test_priv = dataset_priv_test.labels\n",
    "\n",
    "# Predictions\n",
    "predictions_priv_fair = []\n",
    "threshold_priv_fair = 0.4555  # Example threshold\n",
    "pos_ind = 1  # Positive class index\n",
    "\n",
    "for prob in model_priv_fair.predict_proba(X_test_priv)[:, pos_ind]:\n",
    "    predictions_priv_fair.append(1 if prob >= threshold_priv_fair else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870f5d7-d2eb-441e-b1eb-173dfa1fea6d",
   "metadata": {},
   "source": [
    "### Evaluate Privacy + Fairness\n",
    "Accuracy\n",
    "Evaluate the accuracy of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5038c8-ad9e-4d65-b2ac-ab2f5dec9374",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_priv_fair = accuracy_score(y_test_priv, predictions_priv_fair)\n",
    "print(f'Test Accuracy (Privacy + Fairness): {accuracy_priv_fair:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793e2da0-b2cb-43ac-87a6-5684e24f6628",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218fa3cc-fa94-4805-b168-8ecca28624ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_priv_fair = confusion_matrix(y_test_priv, predictions_priv_fair)\n",
    "disp_priv_fair = ConfusionMatrixDisplay(confusion_matrix=cm_priv_fair)\n",
    "disp_priv_fair.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165dd126-487f-4745-9171-1a0bad04b1e2",
   "metadata": {},
   "source": [
    "Fairness Metric calculated using the real age and sex values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18475e0e-a00a-4051-9772-3acc08cad8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_priv_test_pred = dataset_priv_test.copy(deepcopy=True)\n",
    "dataset_priv_test_pred.scores = model_priv_fair.predict_proba(X_test_priv)[:, pos_ind].reshape(-1, 1)\n",
    "\n",
    "fav_inds_priv = dataset_priv_test_pred.scores > threshold_priv_fair\n",
    "dataset_priv_test_pred.labels[fav_inds_priv] = dataset_priv_test_pred.favorable_label\n",
    "dataset_priv_test_pred.labels[~fav_inds_priv] = dataset_priv_test_pred.unfavorable_label\n",
    "\n",
    "eod_priv_fair = ClassificationMetric(\n",
    "    # dataset_priv_test\n",
    "    dataset_fair_test\n",
    "    , dataset_priv_test_pred,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups\n",
    ").equal_opportunity_difference()\n",
    "\n",
    "print(f'Equal Opportunity Difference (Privacy + Fairness): {eod_priv_fair:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b8b953-c89f-420c-adf5-4d22a8a78d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example values (replace with actual results)\n",
    "models = ['Fairness-Only', 'Privacy+Fairness']\n",
    "# accuracy_met=accuracy\n",
    "accuracy = [accuracy_fair, accuracy_priv_fair]\n",
    "fairness = [equal_opportunity_diff_metric, eod_priv_fair]  # EOD values (lower is better)\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(fairness, accuracy, color=['green', 'orange'], s=100, label=models)\n",
    "\n",
    "# Annotate points\n",
    "for i, model in enumerate(models):\n",
    "    plt.text(fairness[i] + 0.01, accuracy[i], model, fontsize=10)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Fairness (EOD)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. Fairness Trade-off')\n",
    "plt.axhline(y=max(accuracy), color='gray', linestyle='--', label='Max Accuracy')\n",
    "plt.axvline(x=min(fairness), color='red', linestyle='--', label='Max Fairness')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a14287-7a08-4f26-a84f-697838fd7b39",
   "metadata": {},
   "source": [
    "As expected the accuracy of the fairness only classifier is higher because the model is trained on the unaltered data. On the other hand, adding privacy via the Local Differential Privacy introduces noise to sensitive attributes, which leads to less accurate models because the underlying data quality is degraded. When combined with fairness adjustments, the performance further decreases because these adjustments reduce bias but may also reduce model fit. Moreover, the noise from the privacy mechanisms adds noise to sensitive attributes. \n",
    "This noise:\n",
    "\n",
    "1- Makes it harder to accurately distinguish between privileged and unprivileged groups.\n",
    "\n",
    "2- Could lead to unintentional oversampling or misclassification of the unprivileged group as privileged during fairness adjustments, or vice versa.\n",
    "\n",
    "3- If the noise disproportionately affects the privileged group, it may unintentionally boost the TPR for the unprivileged group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a50f76-4a49-407d-a2fb-a0de4e12c8b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnixai",
   "language": "python",
   "name": "omnixai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
