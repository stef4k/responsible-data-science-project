{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c8f238-7f91-4150-a7d7-72e8cf37bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1715ab-c7ed-48e1-8a07-9c477a66f226",
   "metadata": {},
   "source": [
    "## Load Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c09b850-68f8-4bb2-991b-dbc6beb4e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only needed columns\n",
    "feature_names = [\n",
    "    \"Age\", \"Workclass\", \"Education\", \n",
    "    \"Occupation\", \"Relationship\", \"Race\", \n",
    "    \"Sex\", \"Capital Gain\", \"Capital Loss\", \n",
    "    \"Hours per week\", \"Country\", \"label\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "  np.genfromtxt('dataset/adult.csv', delimiter=', ', dtype=str, usecols=(0,1,3,6,7,8,9,10,11,12,13,14)),    \n",
    "  columns=feature_names\n",
    ")\n",
    "\n",
    "# Drop missing values denoted as ?\n",
    "cols = list(df.columns)\n",
    "df[cols] = df[cols].replace(['?'], np.nan)\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "# Declare categorical columns\n",
    "categorical_columns=[\n",
    "   \"Workclass\", \"Education\", \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Country\", \"label\"\n",
    "]\n",
    "\n",
    "# Assign type to features\n",
    "for feature in feature_names:\n",
    "    if feature in categorical_columns:\n",
    "        df[feature] = df[feature].astype(\"category\")\n",
    "    else:\n",
    "        df[feature] = df[feature].astype(\"int\")\n",
    "\n",
    "# Make bins for age and hours per week\n",
    "df['Age'] = pd.cut(df['Age'], bins=[16, 35 , 90],labels=['Young','Aged'])\n",
    "df[\"Hours per week\"] = pd.cut(\n",
    "            x=df[\"Hours per week\"],\n",
    "            bins=[0.9, 25, 39, 40, 55, 100],\n",
    "            labels=[\"PartTime\", \"MidTime\", \"FullTime\", \"OverTime\", \"BrainDrain\"])\n",
    "\n",
    "# Replace \"Husband\" and \"Wife\" values with the unisex \"Married\"\n",
    "df[\"Relationship\"] = df[\"Relationship\"].replace('Husband','Married')\n",
    "df[\"Relationship\"] = df[\"Relationship\"].replace('Wife','Married')\n",
    "\n",
    "# Will have income >50k (1 or 0)\n",
    "df[\"label\"] = df[\"label\"].replace('>50K',1)\n",
    "df[\"label\"] = df[\"label\"].replace('<=50K',0)\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82abdd0-926e-4946-b25b-5385d141f842",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e112092b-8a61-4565-a13e-2e7def2a39f2",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fd9277-5fbe-409e-972d-14042d76eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing to train model\n",
    "from omnixai.data.tabular import Tabular\n",
    "from omnixai.preprocessing.tabular import TabularTransform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tabular_data = Tabular(\n",
    "   df,\n",
    "   categorical_columns=[\n",
    "  \"Age\", \"Workclass\", \"Education\", \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Hours per week\", \"Country\"\n",
    "],\n",
    "   target_column='label'\n",
    ")\n",
    "transformer = TabularTransform().fit(tabular_data)\n",
    "class_names = transformer.class_names\n",
    "x = transformer.transform(tabular_data)\n",
    "\n",
    "# Split data into training and (validation + test) datasets\n",
    "train, X_temp, train_labels, y_temp  = \\\n",
    "    train_test_split(x[:, :-1], x[:, -1], train_size=0.70, random_state = 123)\n",
    "\n",
    "# Split data validation and test sets\n",
    "val, test, val_labels, test_labels = train_test_split(X_temp, y_temp, test_size=0.5, random_state=123)\n",
    "\n",
    "test_labels = test_labels.astype(int)\n",
    "\n",
    "print('Training data shape:   {}'.format(train.shape))\n",
    "print('Validation data shape:  {}'.format(val.shape))\n",
    "print('Test data shape:        {}'.format(test.shape))\n",
    "\n",
    "# Train a Random Forest model\n",
    "model = RandomForestClassifier(random_state=123)\n",
    "model.fit(train, train_labels)\n",
    "\n",
    "predict_function=lambda z: model.predict_proba(transformer.transform(z))\n",
    "\n",
    "# Convert the transformed data back to Tabular instances\n",
    "train_data = transformer.invert(train)\n",
    "test_data = transformer.invert(test)\n",
    "\n",
    "display(tabular_data.target_column)\n",
    "display(train_labels[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2976258-ac1a-4bac-b9b7-dfad5f7ede64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Predictions\n",
    "test_df = test_data.to_pd()\n",
    "test_df[\"label\"] = test_labels\n",
    "predictions = model.predict(test)\n",
    "test_df[\"prediction\"] = predictions\n",
    "\n",
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04761915-3a1a-4df6-8947-ce527263a62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f'Test: {accuracy=:.4f}')\n",
    "\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "\n",
    "TN = cm[0][0]\n",
    "FN = cm[1][0]\n",
    "TP = cm[1][1]\n",
    "FP = cm[0][1]\n",
    "print(f\"Test: {TP=}, {TN=}, {FP=}, {FN=}\")\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, )\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46760902",
   "metadata": {},
   "source": [
    "## Fairness\n",
    "Now the fairness will be analyzed\n",
    "\n",
    "First we import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a1992-ab24-4e1b-a52e-b1bf19be7a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "import random\n",
    "from aif360.metrics import ClassificationMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9380a5-042f-4188-85f8-bc485232370b",
   "metadata": {},
   "source": [
    "Since for the fairness analysis, we can not use the Tabular data, we create a new dataframe with the transformed values of TabularTransform. This is because we need to have access to a dataframe structure containing the binarized values (for age, sex and all categorical attributes) and not the categorical values (e.g. Young/Aged, Female/Male etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e414966-fefd-47c8-84ed-0dafc180a348",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = transformer.get_feature_names()\n",
    "# Last column is the label which is not included in the get_feature_names\n",
    "column_names.append('label')\n",
    "\n",
    "fairness_dataset = pd.DataFrame(x, columns=column_names)\n",
    "fairness_dataset.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67441c00-008d-4a34-9076-febbfee68d45",
   "metadata": {},
   "source": [
    "As seen below there are four columns for the protected attributes of sex and age. Two boolean columns for each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f4bcd7-c809-4f64-8719-d5930e832940",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_dataset[['Age_Aged', 'Age_Young', 'Sex_Male', 'Sex_Female']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cd035d-69e3-48d3-8e6e-5497bf6695b0",
   "metadata": {},
   "source": [
    "We decide only to keep `Age_Aged` and `Sex_Male`, and renaming those to columns to `Age` and `Sex` meaning that:\n",
    "- when `Sex` is 0, the person is female and when when `Sex` is 1, the person is male\n",
    "- when `Age` is 0, the person is young and  when `Age` is 0, the person is aged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2263308a-4403-4d99-87aa-9339cc1bb5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_dataset = fairness_dataset.drop(columns=['Age_Young', 'Sex_Female'])\n",
    "fairness_dataset.rename(columns={'Age_Aged': 'Age', 'Sex_Male': 'Sex'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f149d9-c863-4efa-8a4f-67a62ab460ef",
   "metadata": {},
   "source": [
    "Next we want to ensure that we train the classifier on the exact same data as the previous normal classifier, keeping the train, validation and test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ee85cf-da53-48df-adee-04f476f739ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and (validation + test) datasets\n",
    "train, X_temp, _, y_temp  = \\\n",
    "    train_test_split(fairness_dataset, fairness_dataset.label, train_size=0.70, random_state = 123)\n",
    "\n",
    "# Split data validation and test sets\n",
    "val, test, _, _ = train_test_split(X_temp, y_temp, test_size=0.5, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ef0d7f-e38f-427b-8ebd-34d99f8653af",
   "metadata": {},
   "source": [
    "Now we can transform the previous data structures into BinaryLabelDatasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e8fad-eab3-4451-8278-f056bc2b68ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to BinaryLabelDataset\n",
    "dataset_fair_train = BinaryLabelDataset(df=train, label_names=['label'], protected_attribute_names=['Age', 'Sex'])\n",
    "dataset_fair_valid = BinaryLabelDataset(df=val, label_names=['label'], protected_attribute_names=['Age', 'Sex'])\n",
    "dataset_fair_test = BinaryLabelDataset(df=test, label_names=['label'], protected_attribute_names=['Age', 'Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a5ee5a-fe59-43ae-9169-095a99009cb7",
   "metadata": {},
   "source": [
    "Now the group fairness of the classifier will be assessed, assuming the protected attributes are Age, Sex.\n",
    "\n",
    "We assume that:\n",
    "- Young age (corresponding to 0) is one unprivileged group and Aged (corresponding to 1) is one privileged group\n",
    "- Female sex is one unprivileged (corresponding to 0) group and male sex (corresponding to 1) is one privileged group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c29bcf-b09b-4a1b-8ca2-f3a840d6a66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'Age':1,\n",
    "                      'Sex':1}]\n",
    "unprivileged_groups = [{'Age': 0,\n",
    "                       'Sex':0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782e714e-9d6c-418d-bd8b-819c10c4d85a",
   "metadata": {},
   "source": [
    "Since there is a significant difference in the positive rates and true positive rate thus there is unfairness. Actually, the priviliged groups (aged and male) has 37% more chance to be predicted as >50k income comparing to the unprivileged group (young, female)\n",
    "\n",
    "Now, we will try to mitigate this bias in the training dataset by using the `Reweighing algorithm`. By reweighing we ensure that there is better fairness when we compare the positive rates between privileged and unprivileged groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f7198-4ec2-4a0f-8f7d-d5029ef45a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "dataset_transf_train = RW.fit_transform(dataset_fair_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3b4cea-7088-468c-950f-c636d1f83e8c",
   "metadata": {},
   "source": [
    "### Fair classifier\n",
    "\n",
    "Since reweighting does not achieve the goal of $0$ statistical parity difference or Equal opportunity difference, we will oversample the underprivileged classes (female young) and undersample the privileged classes (male aged) to teach the classifier to be more fair. After some experimentation, it was decided:\n",
    "- $750$ extra samples of young female with income >50k were randomly oversampled in the training data, and random weights of values between $[1.2,1.6]$ were given for each sample\n",
    "- $1500$ samples of aged male with income >50k were randomly undersampled in the training data (completely removed from the training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d4be2-61e1-4082-979d-c32d026ce8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed to reproduce results\n",
    "random.seed(1)\n",
    "\n",
    "# Number of over-samples produced for training dataset\n",
    "number_oversamples = 750\n",
    "# Number of under-samples to be removed for training dataset\n",
    "number_undersamples = 1500\n",
    "\n",
    "# Train and target data\n",
    "X_train = dataset_transf_train.features\n",
    "y_train = dataset_transf_train.labels.ravel()\n",
    "\n",
    "# Resampled data structures\n",
    "X_train_resampled = X_train.copy()\n",
    "y_train_resampled = y_train.copy()\n",
    "weights_resampled = dataset_transf_train.instance_weights.copy()\n",
    "\n",
    "# list to keep for indexes of undersamples (to be deleted after)\n",
    "list_indexes_undersamples = []\n",
    "# List to keep the over_samples and counters of oversamples and undersamples\n",
    "oversamples = []\n",
    "counter_oversamples = 0\n",
    "counter_undersamples = 0\n",
    "\n",
    "# Iterate over the whole training dataset\n",
    "for counter in range(len(X_train)):\n",
    "    # Only append rows that contain young female since this is the heavily underprivileged class\n",
    "    if (X_train[counter][0] == 0) and (X_train[counter][1] == 0) and (y_train[counter] == 1)\\\n",
    "        and (counter_oversamples < number_oversamples):\n",
    "        oversamples.append(X_train[counter].copy())\n",
    "        counter_oversamples += 1\n",
    "    # Store index of rows that contain aged male since this is the heavily overprivileged class\n",
    "    if ((X_train[counter][0] == 1) or (X_train[counter][1] == 1)) and (y_train[counter] == 1)\\\n",
    "        and (counter_undersamples < number_undersamples):\n",
    "        list_indexes_undersamples.append(counter)\n",
    "        counter_undersamples += 1\n",
    "    # When number of extra oversamples and undersamples is reached, stop loop\n",
    "    if (counter_oversamples == number_oversamples) and (counter_undersamples == number_undersamples):\n",
    "        break\n",
    "    counter += 1\n",
    "\n",
    "# Remove all indexes of undersamples\n",
    "X_train_resampled = np.delete(X_train_resampled, list_indexes_undersamples, axis=0)\n",
    "y_train_resampled = np.delete(y_train_resampled, list_indexes_undersamples)\n",
    "weights_resampled = np.delete(weights_resampled, list_indexes_undersamples)\n",
    "\n",
    "\n",
    "# Only assign positive labels to favor underprivileged class \n",
    "arr = np.array([1 for i in range(number_oversamples)])\n",
    "\n",
    "# Append extra samples and labels to the training data and \n",
    "y_train_resampled = np.append(y_train_resampled, arr)\n",
    "X_train_resampled = np.vstack([X_train_resampled, oversamples])\n",
    "# Randomize weights of extra samples to take values between 1 and 1.5\n",
    "weights_resampled = np.append(weights_resampled, np.array([random.uniform(1.2, 1.6) for i in range(number_oversamples)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621f0b73-2378-4fce-a54d-bafb2c38a49a",
   "metadata": {},
   "source": [
    "Now we can train the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03636381-824f-40c2-bf21-96486fc2838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fair_reweighted = RandomForestClassifier(random_state=123)\n",
    "model_fair_reweighted.fit(X_train_resampled, y_train_resampled, sample_weight=weights_resampled)\n",
    "\n",
    "X_test = dataset_fair_test.features\n",
    "y_test = dataset_fair_test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb5a56f-13a1-48fc-a1fd-9febf87f9d5f",
   "metadata": {},
   "source": [
    "Next predict the test data <b> based on the threshold </b> found in the fairness analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a3357-cf61-42e8-83e0-4742eef04306",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "threshold_fairness = 0.4555\n",
    "# positive class index\n",
    "pos_ind = 1\n",
    "\n",
    "for item in model_fair_reweighted.predict_proba(X_test)[:,pos_ind].reshape(-1,1):\n",
    "    if item >=  threshold_fairness:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c918ff8d-7e7f-434d-bdc6-5108fe334976",
   "metadata": {},
   "source": [
    "Last let's print the metrics for this classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a0060e-40e1-40cf-a064-3bf59639ca8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Test: {accuracy=:.4f}')\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "TN = cm[0][0]\n",
    "FN = cm[1][0]\n",
    "TP = cm[1][1]\n",
    "FP = cm[0][1]\n",
    "print(f\"Test: {TP=}, {TN=}, {FP=}, {FN=}\")\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, )\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8856cf-2370-44aa-9c7b-c878dc2b312f",
   "metadata": {},
   "source": [
    "Also the fairness metric of `equal opportunity difference` will be printed for the fair classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70a783d-6843-432c-8c67-853b61dc7bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation of predictions dateset - transform into BinaryLabelDataset with right predictions based on the fairness threshold\n",
    "dataset_fair_test_pred = dataset_fair_test.copy(deepcopy=True)\n",
    "dataset_fair_test_pred.scores = model_fair_reweighted.predict_proba(X_test)[:,pos_ind].reshape(-1,1)\n",
    "fav_inds = dataset_fair_test_pred.scores > threshold_fairness\n",
    "dataset_fair_test_pred.labels[fav_inds] = dataset_fair_test_pred.favorable_label\n",
    "dataset_fair_test_pred.labels[~fav_inds] = dataset_fair_test_pred.unfavorable_label\n",
    "\n",
    "# Calculate metric\n",
    "equal_opportunity_diff_metric = ClassificationMetric(dataset_fair_test, dataset_fair_test_pred, \n",
    "                                            unprivileged_groups=unprivileged_groups,\n",
    "                                            privileged_groups=privileged_groups).equal_opportunity_difference()\n",
    "print(f'Equal opportunity difference: {equal_opportunity_diff_metric=:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc4139a",
   "metadata": {},
   "source": [
    "## Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5174f0",
   "metadata": {},
   "source": [
    "To start off, let's define a new dataframe similar to the one above, the set the values of p and q for both sensitive attributes and compute for epsilon. For now, both attributes are assumed to have the same p and q, but they can be redefined to any value as seen fit.\n",
    "\n",
    "Random response is applied to the relevant attributes afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdf0b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "# randomized response \n",
    "def rand_resp(x, p=0.75, q=0.75):\n",
    "    toss = random.random()\n",
    "    if x == 0:\n",
    "        y = 0 if toss <= q else 1\n",
    "    else:\n",
    "        y = 1 if toss <= p else 0\n",
    "    return y\n",
    "\n",
    "def get_epsilon(p=0.75, q=0.75):\n",
    "    return math.log( max(q/(1-p), p/(1-q)) )\n",
    "\n",
    "# apply attribute to a attribute\n",
    "def privatize_attribute(column, true_label, false_label, p, q):\n",
    "    # Convert labels to binary values\n",
    "    binary_values = column.apply(lambda x: 1 if x == true_label else 0).values\n",
    "    \n",
    "    # Apply randomized response\n",
    "    privatized_values = pd.Series([rand_resp(x, p, q) for x in binary_values], index=column.index)\n",
    "\n",
    "    # Convert back to original labels\n",
    "    return privatized_values.apply(lambda x: true_label if x == 1 else false_label)\n",
    "\n",
    "# Create a copy of the original data\n",
    "df_private = df.copy(deep=True)\n",
    "\n",
    "# Set values of p and q\n",
    "p_age, q_age = 0.8, 0.8\n",
    "p_sex, q_sex = 0.8, 0.8  \n",
    "\n",
    "epsilon_age = get_epsilon(p_age, q_age)\n",
    "epsilon_sex = get_epsilon(p_sex, q_sex)\n",
    "print(f\"We will apply {epsilon_age:.3f}-LDP setting p={p_age}, q={q_age} for age \\\n",
    "AND {epsilon_sex:.3f}-LDP setting p={p_sex}, q={q_sex} for sex.\")\n",
    "\n",
    "# Apply randomized response to Age and Sex\n",
    "df_private['Age'] = privatize_attribute(df_private['Age'], 'Aged', 'Young', p_age, q_age)\n",
    "df_private['Sex'] = privatize_attribute(df_private['Sex'], 'Male', 'Female', p_sex, q_sex)\n",
    "\n",
    "# Display the new DataFrame\n",
    "df_private.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61ccbd6",
   "metadata": {},
   "source": [
    "We compute the cross-tabulation on the original data and private data to estimate how many people exist in value combinations of the two sensitive attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc92407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Showing cross tabulation\n",
    "print(\"\\nOriginal Cross-tabulation:\")\n",
    "original_crosstab = pd.crosstab(df['Age'], df['Sex'])\n",
    "print(tabulate(original_crosstab, headers='keys', tablefmt='pretty'))\n",
    "\n",
    "print(\"\\nPrivatized Cross-tabulation:\")\n",
    "privatized_crosstab = pd.crosstab(df_private['Age'], df_private['Sex'])\n",
    "print(tabulate(privatized_crosstab, headers='keys', tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246286dc",
   "metadata": {},
   "source": [
    "Compute the error between the privatized and the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dc3e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_error(true_value, estimated_value):\n",
    "\n",
    "    if true_value == 0:\n",
    "        # If the true value is zero, the percent error is undefined.\n",
    "        return float('inf')\n",
    "    \n",
    "    # Calculate the absolute difference\n",
    "    abs_error = abs(true_value - estimated_value)\n",
    "        \n",
    "    # Calculate the percent error\n",
    "    pct_error = (abs_error / true_value) * 100\n",
    "        \n",
    "    return pct_error\n",
    "\n",
    "\n",
    "error_female_young = pct_error(original_crosstab[\"Female\"][\"Young\"], privatized_crosstab[\"Female\"][\"Young\"])\n",
    "print(f\"The percent error for young female responses is: {error_female_young}%\")\n",
    "\n",
    "error_female_aged = pct_error(original_crosstab[\"Female\"][\"Aged\"], privatized_crosstab[\"Female\"][\"Aged\"])\n",
    "print(f\"The percent error for aged female responses is: {error_female_aged}%\")\n",
    "\n",
    "error_male_young = pct_error(original_crosstab[\"Male\"][\"Young\"], privatized_crosstab[\"Male\"][\"Young\"])\n",
    "print(f\"The percent error for young male responses is: {error_male_young}%\")\n",
    "\n",
    "error_male_aged = pct_error(original_crosstab[\"Male\"][\"Aged\"], privatized_crosstab[\"Male\"][\"Aged\"])\n",
    "print(f\"The percent error for aged male responses is: {error_male_aged}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0807f1",
   "metadata": {},
   "source": [
    "Estimating the actual responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446671ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate(column, p=0.75, q=0.75):\n",
    "    n_people = len(column)\n",
    "    n_reported = np.sum(column.astype(int))\n",
    "    return (n_reported/n_people + q - 1)/(p+q-1)*n_people\n",
    "\n",
    "# insert estimate here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f980363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Private Classifier\n",
    "\n",
    "tabular_data_private = Tabular(\n",
    "   df_private,\n",
    "   categorical_columns=[\n",
    "  \"Age\", \"Workclass\", \"Education\", \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Hours per week\", \"Country\"\n",
    "],\n",
    "   target_column='label'\n",
    ")\n",
    "transformer_private = TabularTransform().fit(tabular_data_private)\n",
    "class_names = transformer_private.class_names\n",
    "x_private = transformer_private.transform(tabular_data_private)\n",
    "\n",
    "# Split data into training and (validation + test) datasets\n",
    "train_private, X_private_temp, train_labels_private, y_private_temp  = \\\n",
    "    train_test_split(x_private[:, :-1], x_private[:, -1], train_size=0.70, random_state = 123)\n",
    "\n",
    "# Split data validation and test sets\n",
    "val_private, test_private, val_labels_private, test_labels_private = train_test_split(X_private_temp, y_private_temp, test_size=0.5, random_state=123)\n",
    "\n",
    "test_labels_private = test_labels_private.astype(int)\n",
    "\n",
    "print('Private Classfier')\n",
    "print('Training data shape:   {}'.format(train_private.shape))\n",
    "print('Validation data shape:  {}'.format(val_private.shape))\n",
    "print('Test data shape:        {}'.format(test_private.shape))\n",
    "\n",
    "# Train a Random Forest model\n",
    "model_private = RandomForestClassifier(random_state=123)\n",
    "model_private.fit(train_private, train_labels_private)\n",
    "\n",
    "predict_function_private=lambda z: model_private.predict_proba(transformer_private.transform(z))\n",
    "\n",
    "# # Convert the transformed data back to Tabular instances\n",
    "train_data_private = transformer_private.invert(train_private)\n",
    "test_data_private = transformer_private.invert(test_private)\n",
    "\n",
    "display(tabular_data_private.target_column)\n",
    "display(train_labels_private[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e25585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Predictions\n",
    "test_df_private = test_data_private.to_pd()\n",
    "test_df_private[\"label\"] = test_labels_private\n",
    "predictions_private = model_private.predict(test_private)\n",
    "test_df_private[\"prediction\"] = predictions_private\n",
    "\n",
    "test_df_private.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cca831",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_private = accuracy_score(test_labels_private, predictions_private)\n",
    "print(f'Test: {accuracy_private=:.4f}')\n",
    "\n",
    "cm_private = confusion_matrix(test_labels_private, predictions_private)\n",
    "\n",
    "TN = cm_private[0][0]\n",
    "FN = cm_private[1][0]\n",
    "TP = cm_private[1][1]\n",
    "FP = cm_private[0][1]\n",
    "print(f\"Test: {TP=}, {TN=}, {FP=}, {FN=}\")\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_private, )\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4359d9",
   "metadata": {},
   "source": [
    "The accuracy lowered as expected. Implementing differential privacy involves adding noise to the training process to protect individual data points. This added noise can degrade the model's accuracy, especially as epsilon decreases. Lower epsilon values correspond to stronger privacy guarantees but also result in greater noise, which can lead to decreased model performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BW_myenv",
   "language": "python",
   "name": "omnixai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
